{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 5: Feature Selection and LASSO (Interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will use LASSO to select features, building on a pre-implemented solver for LASSO (using GraphLab Create, though you can use other solvers). You will:\n",
    "* Run LASSO with different L1 penalties.\n",
    "* Choose best L1 penalty using a validation set.\n",
    "* Choose best L1 penalty using a validation set, with additional constraint on the size of subset.\n",
    "\n",
    "In the second notebook, you will implement your own LASSO solver, using coordinate descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up graphlab create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales = graphlab.SFrame('kc_house_data.gl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Week 2, we consider features that are some transformations of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "\n",
    "# In the dataset, 'floors' was defined with type string, \n",
    "# so we'll convert them to float, before creating a new feature.\n",
    "sales['floors'] = sales['floors'].astype(float) \n",
    "sales['floors_square'] = sales['floors']*sales['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\n",
    "* On the other hand, taking square root of sqft_living will decrease the separation between big house and small house. The owner may not be exactly twice as happy for getting a house that is twice as big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn regression weights with L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fit a model with all the features available, plus the features we just created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_features = ['bedrooms', 'bedrooms_square',\n",
    "            'bathrooms',\n",
    "            'sqft_living', 'sqft_living_sqrt',\n",
    "            'sqft_lot', 'sqft_lot_sqrt',\n",
    "            'floors', 'floors_square',\n",
    "            'waterfront', 'view', 'condition', 'grade',\n",
    "            'sqft_above',\n",
    "            'sqft_basement',\n",
    "            'yr_built', 'yr_renovated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying L1 penalty requires adding an extra parameter (`l1_penalty`) to the linear regression call in GraphLab Create. (Other tools may have separate implementations of LASSO.)  Note that it's important to set `l2_penalty=0` to ensure we don't introduce an additional L2 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Linear regression:</pre>"
      ],
      "text/plain": [
       "Linear regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 21613</pre>"
      ],
      "text/plain": [
       "Number of examples          : 21613"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of features          : 17</pre>"
      ],
      "text/plain": [
       "Number of features          : 17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 17</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 18</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting Accelerated Gradient (FISTA)</pre>"
      ],
      "text/plain": [
       "Starting Accelerated Gradient (FISTA)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+--------------------+---------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+--------------------+---------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-max_error | Training-rmse |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-max_error | Training-rmse |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+--------------------+---------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+--------------------+---------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Tuning step size. First iteration could take longer than subsequent iterations.</pre>"
      ],
      "text/plain": [
       "Tuning step size. First iteration could take longer than subsequent iterations."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 2        | 0.000002  | 0.303058     | 6962915.603493     | 426631.749026 |</pre>"
      ],
      "text/plain": [
       "| 1         | 2        | 0.000002  | 0.303058     | 6962915.603493     | 426631.749026 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 3        | 0.000002  | 0.328093     | 6843144.200219     | 392488.929838 |</pre>"
      ],
      "text/plain": [
       "| 2         | 3        | 0.000002  | 0.328093     | 6843144.200219     | 392488.929838 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 4        | 0.000002  | 0.359155     | 6831900.032123     | 385340.166783 |</pre>"
      ],
      "text/plain": [
       "| 3         | 4        | 0.000002  | 0.359155     | 6831900.032123     | 385340.166783 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 5        | 0.000002  | 0.387787     | 6847166.848958     | 384842.383767 |</pre>"
      ],
      "text/plain": [
       "| 4         | 5        | 0.000002  | 0.387787     | 6847166.848958     | 384842.383767 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 6        | 0.000002  | 0.413797     | 6869667.895833     | 385998.458623 |</pre>"
      ],
      "text/plain": [
       "| 5         | 6        | 0.000002  | 0.413797     | 6869667.895833     | 385998.458623 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 7        | 0.000002  | 0.440041     | 6847177.773672     | 380824.455891 |</pre>"
      ],
      "text/plain": [
       "| 6         | 7        | 0.000002  | 0.440041     | 6847177.773672     | 380824.455891 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+--------------------+---------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+--------------------+---------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>TERMINATED: Iteration limit reached.</pre>"
      ],
      "text/plain": [
       "TERMINATED: Iteration limit reached."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>This model may not be optimal. To improve it, consider increasing `max_iterations`.</pre>"
      ],
      "text/plain": [
       "This model may not be optimal. To improve it, consider increasing `max_iterations`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_all = graphlab.linear_regression.create(sales, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=1e10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find what features had non-zero weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+---------------+--------+\n",
      "|       name       | index |     value     | stderr |\n",
      "+------------------+-------+---------------+--------+\n",
      "|   (intercept)    |  None |  274873.05595 |  None  |\n",
      "|     bedrooms     |  None |      0.0      |  None  |\n",
      "| bedrooms_square  |  None |      0.0      |  None  |\n",
      "|    bathrooms     |  None | 8468.53108691 |  None  |\n",
      "|   sqft_living    |  None | 24.4207209824 |  None  |\n",
      "| sqft_living_sqrt |  None | 350.060553386 |  None  |\n",
      "|     sqft_lot     |  None |      0.0      |  None  |\n",
      "|  sqft_lot_sqrt   |  None |      0.0      |  None  |\n",
      "|      floors      |  None |      0.0      |  None  |\n",
      "|  floors_square   |  None |      0.0      |  None  |\n",
      "|    waterfront    |  None |      0.0      |  None  |\n",
      "|       view       |  None |      0.0      |  None  |\n",
      "|    condition     |  None |      0.0      |  None  |\n",
      "|      grade       |  None | 842.068034898 |  None  |\n",
      "|    sqft_above    |  None | 20.0247224171 |  None  |\n",
      "|  sqft_basement   |  None |      0.0      |  None  |\n",
      "|     yr_built     |  None |      0.0      |  None  |\n",
      "|   yr_renovated   |  None |      0.0      |  None  |\n",
      "+------------------+-------+---------------+--------+\n",
      "[18 rows x 4 columns]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all.get(\"coefficients\").print_rows(num_rows=len(all_features)+2)\n",
    "model_all[\"coefficients\"][\"value\"].nnz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a majority of the weights have been set to zero. So by setting an L1 penalty that's large enough, we are performing a subset selection. \n",
    "\n",
    "***QUIZ QUESTION***:\n",
    "According to this list of weights, which of the features have been chosen? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting an L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a good L1 penalty, we will explore multiple values using a validation set. Let us do three way split into train, validation, and test sets:\n",
    "* Split our sales data into 2 sets: training and test\n",
    "* Further split our training data into two sets: train, validation\n",
    "\n",
    "Be *very* careful that you use seed = 1 to ensure you get the same answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(training_and_validation, testing) = sales.random_split(.9,seed=1) # initial train/test split\n",
    "(training, validation) = training_and_validation.random_split(0.5, seed=1) # split training into train and validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a loop that does the following:\n",
    "* For `l1_penalty` in [10^1, 10^1.5, 10^2, 10^2.5, ..., 10^7] (to get this in Python, type `np.logspace(1, 7, num=13)`.)\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list.\n",
    "    * Compute the RSS on VALIDATION data (here you will want to use `.predict()`) for that `l1_penalty`\n",
    "* Report which `l1_penalty` produced the lowest RSS on validation data.\n",
    "\n",
    "When you call `linear_regression.create()` make sure you set `validation_set = None`.\n",
    "\n",
    "Note: you can turn off the print out of `linear_regression.create()` with `verbose = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Penalty\t\tRSS\n",
      "10\t\t625766285142460\n",
      "31\t\t625766285362394\n",
      "100\t\t625766286057885\n",
      "316\t\t625766288257224\n",
      "1000\t\t625766295212186\n",
      "3162\t\t625766317206081\n",
      "10000\t\t625766386760658\n",
      "31622\t\t625766606749278\n",
      "100000\t\t625767302791635\n",
      "316227\t\t625769507643886\n",
      "1000000\t\t625776517727024\n",
      "3162277\t\t625799062845467\n",
      "10000000\t\t625883719085425\n",
      "10.0 6.25766285142e+14\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAELCAYAAAA86fb3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11debc190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def get_residual_sum_of_squares(model, data, outcome):\n",
    "    # First get the predictions\n",
    "    pred = model.predict(data)\n",
    "    # Then compute the residuals/errors\n",
    "    res =  pred - outcome\n",
    "    # Then square and add them up\n",
    "    RSS =  (res * res).sum() #np.dot(res,res).sum()\n",
    "    return(RSS)\n",
    "\n",
    "print \"L1 Penalty\\t\\tRSS\"\n",
    "x = []\n",
    "y = []\n",
    "minrss = 1e40\n",
    "minpenalty = 0\n",
    "\n",
    "for l1p in np.logspace(1, 7, num=13):\n",
    "    mdl = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                     validation_set=None, l2_penalty=0., \n",
    "                                     l1_penalty=l1p, verbose= False)\n",
    "    rssval = get_residual_sum_of_squares(mdl,validation,validation['price'])\n",
    "    \n",
    "    print \"%d\\t\\t%0.0f\" % (l1p, rssval)\n",
    "    x.append(l1p)\n",
    "    y.append(rssval)\n",
    "    if rssval < minrss:\n",
    "        minrss = rssval\n",
    "        minpenalty = l1p\n",
    "    \n",
    "print minpenalty, minrss\n",
    "plt.plot(x,y,'*')\n",
    "plt.xscale('log')    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTIONS ***\n",
    "1. What was the best value for the `l1_penalty`?\n",
    "2. What is the RSS on TEST data of the model with the best `l1_penalty`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.56972779669e+14\n"
     ]
    }
   ],
   "source": [
    "mdlbest = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                     validation_set=None, l2_penalty=0, \n",
    "                                     l1_penalty=10, verbose= False)\n",
    "rsstest = get_residual_sum_of_squares(mdl,testing,testing['price'])\n",
    "print rsstest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "Also, using this value of L1 penalty, how many nonzero weights do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+------------------+--------+\n",
      "|       name       | index |      value       | stderr |\n",
      "+------------------+-------+------------------+--------+\n",
      "|   (intercept)    |  None |  18993.4272128   |  None  |\n",
      "|     bedrooms     |  None |  7936.96767903   |  None  |\n",
      "| bedrooms_square  |  None |  936.993368193   |  None  |\n",
      "|    bathrooms     |  None |  25409.5889341   |  None  |\n",
      "|   sqft_living    |  None |  39.1151363797   |  None  |\n",
      "| sqft_living_sqrt |  None |  1124.65021281   |  None  |\n",
      "|     sqft_lot     |  None | 0.00348361822299 |  None  |\n",
      "|  sqft_lot_sqrt   |  None |  148.258391011   |  None  |\n",
      "|      floors      |  None |   21204.335467   |  None  |\n",
      "|  floors_square   |  None |  12915.5243361   |  None  |\n",
      "|    waterfront    |  None |  601905.594545   |  None  |\n",
      "|       view       |  None |  93312.8573119   |  None  |\n",
      "|    condition     |  None |  6609.03571245   |  None  |\n",
      "|      grade       |  None |  6206.93999188   |  None  |\n",
      "|    sqft_above    |  None |  43.2870534193   |  None  |\n",
      "|  sqft_basement   |  None |  122.367827534   |  None  |\n",
      "|     yr_built     |  None |  9.43363539372   |  None  |\n",
      "|   yr_renovated   |  None |  56.0720034488   |  None  |\n",
      "+------------------+-------+------------------+--------+\n",
      "[18 rows x 4 columns]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdlbest.get(\"coefficients\").print_rows(num_rows=len(all_features)+2)\n",
    "mdlbest[\"coefficients\"][\"value\"].nnz()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit the number of nonzero weights\n",
    "\n",
    "What if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to implement a simple, two phase procedure to achive this goal:\n",
    "1. Explore a large range of `l1_penalty` values to find a narrow region of `l1_penalty` values where models are likely to have the desired number of non-zero weights.\n",
    "2. Further explore the narrow region you found to find a good value for `l1_penalty` that achieves the desired sparsity.  Here, we will again use a validation set to choose the best value for `l1_penalty`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_nonzeros = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the larger range of values to find a narrow range with the desired sparsity\n",
    "\n",
    "Let's define a wide range of possible `l1_penalty_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.logspace(8, 10, num=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, implement a loop that search through this space of possible `l1_penalty` values:\n",
    "\n",
    "* For `l1_penalty` in `np.logspace(8, 10, num=20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Extract the weights of the model and count the number of nonzeros. Save the number of nonzeros to a list.\n",
    "        * *Hint: `model['coefficients']['value']` gives you an SArray with the parameters you learned.  If you call the method `.nnz()` on it, you will find the number of non-zero parameters!* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Penalty\t\tRSS\n",
      "100000000\t\t18\n",
      "127427498\t\t18\n",
      "162377673\t\t18\n",
      "206913808\t\t18\n",
      "263665089\t\t17\n",
      "335981828\t\t17\n",
      "428133239\t\t17\n",
      "545559478\t\t17\n",
      "695192796\t\t17\n",
      "885866790\t\t16\n",
      "1128837891\t\t15\n",
      "1438449888\t\t15\n",
      "1832980710\t\t13\n",
      "2335721469\t\t12\n",
      "2976351441\t\t10\n",
      "3792690190\t\t6\n",
      "4832930238\t\t5\n",
      "6158482110\t\t3\n",
      "7847599703\t\t1\n",
      "10000000000\t\t1\n",
      "2976351441.63 10\n",
      "3792690190.73 6\n"
     ]
    }
   ],
   "source": [
    "print \"L1 Penalty\\t\\tRSS\"\n",
    "x = []\n",
    "y = []\n",
    "maxnz = 30\n",
    "minnz = 0\n",
    "\n",
    "maxpen = 0\n",
    "minpen = 0\n",
    "\n",
    "\n",
    "for l1p in l1_penalty_values:\n",
    "    mdl = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                     validation_set=None, l2_penalty=0, \n",
    "                                     l1_penalty=l1p, verbose= False)\n",
    "    #rssval = get_residual_sum_of_squares(mdl,validation,validation['price'])\n",
    "    nnz = mdl[\"coefficients\"][\"value\"].nnz()\n",
    "    print \"%d\\t\\t%0.0f\" % (l1p, nnz)\n",
    "    # x.append(l1p)\n",
    "    #y.append(rssval)\n",
    "    if nnz < maxnz and nnz > max_nonzeros:\n",
    "        maxnz = nnz\n",
    "        maxpen = l1p\n",
    "        \n",
    "    if nnz > minnz and nnz < max_nonzeros:\n",
    "        minnz = nnz \n",
    "        minpen = l1p\n",
    "        \n",
    "    \n",
    "print maxpen, maxnz\n",
    "print minpen, minnz\n",
    "# plt.plot(x,y,'*')\n",
    "# plt.xscale('log')    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of this large range, we want to find the two ends of our desired narrow range of `l1_penalty`.  At one end, we will have `l1_penalty` values that have too few non-zeros, and at the other end, we will have an `l1_penalty` that has too many non-zeros.  \n",
    "\n",
    "More formally, find:\n",
    "* The largest `l1_penalty` that has more non-zeros than `max_nonzero` (if we pick a penalty smaller than this value, we will definitely have too many non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_min` (we will use it later)\n",
    "* The smallest `l1_penalty` that has fewer non-zeros than `max_nonzero` (if we pick a penalty larger than this value, we will definitely have too few non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_max` (we will use it later)\n",
    "\n",
    "\n",
    "*Hint: there are many ways to do this, e.g.:*\n",
    "* Programmatically within the loop above\n",
    "* Creating a list with the number of non-zeros for each value of `l1_penalty` and inspecting it to find the appropriate boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_penalty_min = 2976351441.63\n",
    "l1_penalty_max = 3792690190"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "\n",
    "What values did you find for `l1_penalty_min` and`l1_penalty_max`? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the narrow range of values to find the solution with the right number of non-zeros that has lowest RSS on the validation set \n",
    "\n",
    "We will now explore the narrow region of `l1_penalty` values we found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.linspace(l1_penalty_min,l1_penalty_max,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For `l1_penalty` in `np.linspace(l1_penalty_min,l1_penalty_max,20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Measure the RSS of the learned model on the VALIDATION set\n",
    "\n",
    "Find the model that the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzero`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Penalty\t\tRSS\n",
      "2976351442\t\t966925692362085\t\t10\n",
      "3019316639\t\t974019450084555\t\t10\n",
      "3062281836\t\t981188367942454\t\t10\n",
      "3105247033\t\t989328342459474\t\t10\n",
      "3148212231\t\t998783211265890\t\t10\n",
      "3191177428\t\t1008477167020094\t\t10\n",
      "3234142625\t\t1018298780553819\t\t10\n",
      "3277107823\t\t1028247992205977\t\t10\n",
      "3320073020\t\t1034616909232827\t\t8\n",
      "3363038217\t\t1038554735941040\t\t8\n",
      "3406003414\t\t1043237237871701\t\t8\n",
      "3448968612\t\t1046937488751712\t\t7\n",
      "3491933809\t\t1051147625612862\t\t7\n",
      "3534899006\t\t1055992735342999\t\t7\n",
      "3577864204\t\t1060799531763287\t\t7\n",
      "3620829401\t\t1065707689498230\t\t6\n",
      "3663794598\t\t1069464335425585\t\t6\n",
      "3706759795\t\t1073504549585599\t\t6\n",
      "3749724993\t\t1077632775581415\t\t6\n",
      "3792690190\t\t1081867592324112\t\t6\n",
      "2976351441.63 9.66925692362e+14\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAELCAYAAAA/cjqaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH4sUGGbWQNidAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d995c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print \"L1 Penalty\\t\\tRSS\"\n",
    "x = []\n",
    "y = []\n",
    "minrss = 1e40\n",
    "minpenalty = 0\n",
    "z = []\n",
    "\n",
    "for l1p in l1_penalty_values:\n",
    "    mdl = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                     validation_set=None, l2_penalty=0, \n",
    "                                     l1_penalty=l1p, verbose= False)\n",
    "    rssval = get_residual_sum_of_squares(mdl,validation,validation['price'])\n",
    "    nnz = mdl[\"coefficients\"][\"value\"].nnz()\n",
    "    \n",
    "    print \"%0.0f\\t\\t%0.0f\\t\\t%d\" % (l1p, rssval, nnz)\n",
    "    x.append(l1p)\n",
    "    y.append(rssval)\n",
    "    z.append(nnz)\n",
    "    if rssval < minrss:\n",
    "        minrss = rssval\n",
    "        minpenalty = l1p\n",
    "    \n",
    "print minpenalty, minrss\n",
    "plt.plot(x,y,'*')\n",
    "plt.xscale('log')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "1. What value of `l1_penalty` in our narrow range has the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`?\n",
    "2. What features in this model have non-zero coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdl = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                     validation_set=None, l2_penalty=0, \n",
    "                                     l1_penalty=3448968612, verbose= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+---------------+--------+\n",
      "|       name       | index |     value     | stderr |\n",
      "+------------------+-------+---------------+--------+\n",
      "|   (intercept)    |  None | 222253.192544 |  None  |\n",
      "|     bedrooms     |  None | 661.722717782 |  None  |\n",
      "| bedrooms_square  |  None |      0.0      |  None  |\n",
      "|    bathrooms     |  None | 15873.9572593 |  None  |\n",
      "|   sqft_living    |  None | 32.4102214513 |  None  |\n",
      "| sqft_living_sqrt |  None | 690.114773313 |  None  |\n",
      "|     sqft_lot     |  None |      0.0      |  None  |\n",
      "|  sqft_lot_sqrt   |  None |      0.0      |  None  |\n",
      "|      floors      |  None |      0.0      |  None  |\n",
      "|  floors_square   |  None |      0.0      |  None  |\n",
      "|    waterfront    |  None |      0.0      |  None  |\n",
      "|       view       |  None |      0.0      |  None  |\n",
      "|    condition     |  None |      0.0      |  None  |\n",
      "|      grade       |  None | 2899.42026975 |  None  |\n",
      "|    sqft_above    |  None | 30.0115753022 |  None  |\n",
      "|  sqft_basement   |  None |      0.0      |  None  |\n",
      "|     yr_built     |  None |      0.0      |  None  |\n",
      "|   yr_renovated   |  None |      0.0      |  None  |\n",
      "+------------------+-------+---------------+--------+\n",
      "[18 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mdl.get(\"coefficients\").print_rows(num_rows=len(all_features)+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
